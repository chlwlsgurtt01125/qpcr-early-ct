# app/streamlit_app.py
from __future__ import annotations

import io
import re
import sys
import json
import subprocess
from datetime import datetime
from pathlib import Path
import numpy as np
import pandas as pd
import streamlit as st
import xgboost as xgb

from core.model_features import build_x_from_long

PROJECT_ROOT = Path(__file__).resolve().parents[1]
MODELS_DIR = PROJECT_ROOT / "data" / "models" / "by_cutoff"
UPLOAD_DIR = PROJECT_ROOT / "data" / "uploads"

st.set_page_config(page_title="qPCR Ct Early Prediction", layout="wide")


# -------------------------
# Utilities
# -------------------------
def _safe_stem(name: str) -> str:
    s = Path(name).stem
    s = re.sub(r"[^a-zA-Z0-9_\-]+", "_", s)
    return s[:80] if s else "uploaded"


def discover_cutoffs(models_dir: Path) -> list[int]:
    cutoffs: list[int] = []
    for p in models_dir.glob("ct_xgb_cutoff_*.json"):
        m = re.search(r"cutoff_(\d+)\.json$", p.name)
        if m:
            cutoffs.append(int(m.group(1)))
    return sorted(set(cutoffs))


@st.cache_resource
def load_booster(cutoff: int) -> xgb.Booster:
    model_path = MODELS_DIR / f"ct_xgb_cutoff_{cutoff}.json"
    booster = xgb.Booster()
    booster.load_model(str(model_path))
    return booster


def load_meta(cutoff: int) -> dict:
    meta_path = MODELS_DIR / f"ct_xgb_cutoff_{cutoff}.meta.json"
    if meta_path.exists():
        return json.loads(meta_path.read_text(encoding="utf-8"))
    return {}


def _drop_unnamed(df: pd.DataFrame) -> pd.DataFrame:
    cols = [c for c in df.columns if str(c).lower().startswith("unnamed")]
    return df.drop(columns=cols) if cols else df


def infer_long_df(df: pd.DataFrame, run_id: str) -> pd.DataFrame:
    """
    ì—…ë¡œë“œ í…Œì´ë¸”ì„ ìµœëŒ€í•œ ê´€ëŒ€í•˜ê²Œ long í˜•íƒœë¡œ ë³€í™˜.
    ìµœì¢… ë°˜í™˜ ì»¬ëŸ¼: Cycle, Fluor, Well, run_id, well_uid

    ì§€ì› í¬ë§·:
      A) long: (Well, Cycle, Fluor/RFU/Signal)
      B) wide-1: (Well + cycle columns "1","2",... ë˜ëŠ” "Cycle 1"...)
      C) wide-2: (Cycle + well columns "C3","C5","A01"... )  <-- ë„ˆ ì¼€ì´ìŠ¤
    """
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    df = _drop_unnamed(df)

    cols_lower = {str(c).strip().lower(): c for c in df.columns}

    # ---- A) long í˜•íƒœ: Cycle + (Fluor/RFU/Signal)
    has_cycle = "cycle" in cols_lower
    fluor_key = None
    for k in ("fluor", "rfu", "signal"):
        if k in cols_lower:
            fluor_key = k
            break

    if has_cycle and fluor_key is not None:
        cycle_col = cols_lower["cycle"]
        fluor_col = cols_lower[fluor_key]
        well_col = (
            cols_lower.get("well")
            or cols_lower.get("well position")
            or cols_lower.get("well_position")
        )

        if well_col is None:
            # Wellì´ ì—†ìœ¼ë©´ í–‰ ë²ˆí˜¸ë¡œ ì„ì‹œ well ë¶€ì—¬
            df["Well"] = [f"R{i:03d}" for i in range(1, len(df) + 1)]
            well_col = "Well"

        out = df[[well_col, cycle_col, fluor_col]].copy()
        out.columns = ["Well", "Cycle", "Fluor"]

    # ---- C) Cycle + ì—¬ëŸ¬ well ì»¬ëŸ¼ (Cycleì´ í–‰)
    elif has_cycle:
        cycle_col = cols_lower["cycle"]
        well_cols = [c for c in df.columns if c != cycle_col]
        if not well_cols:
            raise ValueError("Cycle ì»¬ëŸ¼ì€ ìˆëŠ”ë° well ì»¬ëŸ¼(C3, C5, A01 ë“±)ì´ ì—†ì–´.")

        long = df.melt(id_vars=[cycle_col], value_vars=well_cols, var_name="Well", value_name="Fluor")
        long.rename(columns={cycle_col: "Cycle"}, inplace=True)
        out = long[["Well", "Cycle", "Fluor"]].copy()

    # ---- B) Well + cycle ì»¬ëŸ¼ë“¤ (wide)
    else:
        well_col = None
        for cand in ["Well", "well", "WELL"]:
            if cand in df.columns:
                well_col = cand
                break
        if well_col is None:
            raise ValueError("Well ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆì–´. (ì˜ˆ: Well, well)")

        cycle_cols = []
        for c in df.columns:
            if c == well_col:
                continue
            if re.fullmatch(r"\d+", str(c).strip()):
                cycle_cols.append(c)
            elif re.search(r"cycle\s*\d+", str(c).strip(), flags=re.IGNORECASE):
                cycle_cols.append(c)

        if not cycle_cols:
            raise ValueError("longë„ ì•„ë‹ˆê³  wide(Well+cycle cols)ë„ ì•„ë‹Œ ê²ƒ ê°™ì•„. (Cycle+well colsë„ ì•„ë‹˜)")

        tmp = df[[well_col] + cycle_cols].copy()
        long = tmp.melt(id_vars=[well_col], var_name="Cycle", value_name="Fluor")
        long["Cycle"] = long["Cycle"].astype(str).str.extract(r"(\d+)").astype(int)
        long.rename(columns={well_col: "Well"}, inplace=True)
        out = long[["Well", "Cycle", "Fluor"]].copy()

    # ---- ì •ë¦¬
    out = out.dropna(subset=["Well", "Cycle", "Fluor"]).copy()
    out["Cycle"] = pd.to_numeric(out["Cycle"], errors="coerce")
    out["Fluor"] = pd.to_numeric(out["Fluor"], errors="coerce")
    out = out.dropna(subset=["Cycle", "Fluor"]).copy()

    out["Cycle"] = out["Cycle"].astype(int)
    out["run_id"] = run_id
    out["well_uid"] = out["run_id"].astype(str) + ":" + out["Well"].astype(str)

    return out[["Cycle", "Fluor", "Well", "run_id", "well_uid"]]


def predict_ct(df_long: pd.DataFrame, cutoff: int) -> pd.DataFrame:
    booster = load_booster(cutoff)
    X, meta = build_x_from_long(df_long, cutoff=cutoff)

    m = load_meta(cutoff)
    feat_cols = m.get("feat_cols") or m.get("feature_cols")  # í˜¹ì‹œ í‚¤ ì´ë¦„ ë‹¤ë¥¼ê¹Œë´
    if feat_cols:
        dmat = xgb.DMatrix(X, feature_names=list(feat_cols))
    else:
        dmat = xgb.DMatrix(X)

    pred = booster.predict(dmat)

    out = meta.copy()
    out["pred_ct"] = pred.astype(float)
    out["cutoff_used"] = cutoff
    return out.sort_values(["run_id", "Well"]).reset_index(drop=True)


def run_retrain(min_cutoff: int, max_cutoff: int) -> tuple[int, str]:
    """
    í˜„ì¬ ì„œë²„ì— ìˆëŠ” canonical/master_long.parquet ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ ì „ì²´ ì¬í•™ìŠµ.
    """
    cmd = [
        sys.executable, "-m", "core.step3_train_and_save_models",
        "--min_cutoff", str(min_cutoff),
        "--max_cutoff", str(max_cutoff),
    ]
    p = subprocess.run(cmd, cwd=str(PROJECT_ROOT), capture_output=True, text=True)
    log = (p.stdout or "") + "\n" + (p.stderr or "")
    return p.returncode, log


def read_uploaded_table(up) -> pd.DataFrame:
    name = (up.name or "").lower()
    raw = up.read()
    if name.endswith(".xlsx") or name.endswith(".xls"):
        # ì—‘ì…€
        return pd.read_excel(io.BytesIO(raw))
    # csv
    return pd.read_csv(io.BytesIO(raw))


# -------------------------
# UI
# -------------------------
st.title("qPCR Ct ì¡°ê¸° ì˜ˆì¸¡ (Cutoff-based XGBoost)")

cutoffs = discover_cutoffs(MODELS_DIR)
if not cutoffs:
    st.error(f"ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆì–´: {MODELS_DIR} (ct_xgb_cutoff_*.json ì—†ìŒ)")
    st.stop()

with st.sidebar:
    st.header("ì„¤ì •")
    default_cutoff = 30 if 30 in cutoffs else cutoffs[-1]
    cutoff = st.selectbox("Cutoff(ì‚¬ìš© cycle ìˆ˜)", cutoffs, index=cutoffs.index(default_cutoff))

    st.divider()
    st.subheader("ì¬í•™ìŠµ (ì„œë²„ ë°ì´í„° ê¸°ì¤€)")
    min_c = st.number_input("min_cutoff", min_value=1, max_value=200, value=1, step=1)
    max_c = st.number_input("max_cutoff", min_value=1, max_value=200, value=40, step=1)

st.caption("ì—…ë¡œë“œí•œ qPCR curve ë°ì´í„°ë¡œ Ctë¥¼ ì˜ˆì¸¡í•˜ê±°ë‚˜, ì„œë²„ì— ëˆ„ì ëœ ë°ì´í„°ë¡œ ëª¨ë¸ì„ ì¬í•™ìŠµí•  ìˆ˜ ìˆì–´ìš”.")

colA, colB = st.columns([1.2, 1.0], gap="large")

with colA:
    st.subheader("1) ìƒˆ ë°ì´í„° í…ŒìŠ¤íŠ¸ (í•™ìŠµ ì—†ì´ ì˜ˆì¸¡ë§Œ)")
    up = st.file_uploader(
        "CSV/XLSX ì—…ë¡œë“œ (long: Well/Cycle/Fluor ë˜ëŠ” wide: Well+cycle columns ë˜ëŠ” Cycle+well columns)",
        type=["csv", "xlsx", "xls"],
    )

    if up is not None:
        run_id = f"upload_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{_safe_stem(up.name)}"
        raw_bytes = up.getvalue() if hasattr(up, "getvalue") else up.read()

        UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
        ext = ".xlsx" if up.name.lower().endswith((".xlsx", ".xls")) else ".csv"
        saved_path = UPLOAD_DIR / f"{run_id}{ext}"
        saved_path.write_bytes(raw_bytes)

        # ë‹¤ì‹œ bytesë¡œ ì½ê¸° ìœ„í•´ file-like ë§Œë“¤ê¸°
        up_buf = io.BytesIO(raw_bytes)
        if ext in (".xlsx", ".xls"):
            df = pd.read_excel(up_buf)
        else:
            df = pd.read_csv(up_buf)

        st.write("ë¯¸ë¦¬ë³´ê¸°", df.head(10))

        try:
            df_long = infer_long_df(df, run_id=run_id)
            st.success(f"ë³€í™˜ ì„±ê³µ: long rows={len(df_long):,}, wells={df_long['well_uid'].nunique():,}")
            st.dataframe(df_long.head(30), use_container_width=True)

            if st.button("ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
              with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                  pred_df = predict_ct(df_long, cutoff=cutoff)
              st.success(f"ì™„ë£Œ! ì˜ˆì¸¡ wells={len(pred_df):,}")
              st.dataframe(pred_df, use_container_width=True)

        # ---- (ì¶”ê°€) ì—…ë¡œë“œ ë°ì´í„°ì— ì •ë‹µ Ctê°€ ìˆìœ¼ë©´ ì¦‰ì„ í‰ê°€ ----
              true_col = None
              for cand in ["true_ct", "ct", "Ct", "CT", "TrueCt", "trueCt"]:
                if cand in df.columns:
                    true_col = cand
                    break

              if true_col is not None:
                well_key = None
                for w in ["Well", "well", "WELL"]:
                  if w in df.columns:
                      well_key = w
                      break

                if well_key is not None and "Well" in pred_df.columns:
                  truth2 = df[[well_key, true_col]].copy()
                  truth2.columns = ["Well", "true_ct"]
                  eval_df = pred_df.merge(truth2, on="Well", how="left")
                else:
                  eval_df = pred_df.copy()
                  eval_df["true_ct"] = df[true_col].values[:len(eval_df)]

                eval_df = eval_df.dropna(subset=["true_ct"]).copy()
                eval_df["true_ct"] = pd.to_numeric(eval_df["true_ct"], errors="coerce")
                eval_df = eval_df.dropna(subset=["true_ct"]).copy()
        
                eval_df["err"] = eval_df["pred_ct"] - eval_df["true_ct"]
                mae = float(np.mean(np.abs(eval_df["err"])))
                rmse = float(np.sqrt(np.mean(eval_df["err"] ** 2)))
        
                st.markdown("### âœ… ì—…ë¡œë“œ ë°ì´í„° ì¦‰ì„ í‰ê°€")
                st.write({"MAE": mae, "RMSE": rmse, "n": len(eval_df)})
        
                st.markdown("**Pred vs True (ì‚°ì ë„)**")
                st.scatter_chart(eval_df[["true_ct", "pred_ct"]], x="true_ct", y="pred_ct", height=300)
        
                st.markdown("**Residual(ì˜¤ì°¨) ë¶„í¬**")
                st.line_chart(eval_df["err"].value_counts().sort_index(), height=220)
              else:
                  st.info("ì—…ë¡œë“œ íŒŒì¼ì— ì •ë‹µ Ct ì»¬ëŸ¼ì´ ì—†ì–´ì„œ(ì˜ˆ: true_ct/ct) ì¦‰ì„ í‰ê°€ëŠ” ìƒëµí–ˆì–´ìš”.")

                csv_bytes = pred_df.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_bytes,
                    file_name=f"pred_{run_id}_cutoff{cutoff}.csv",
                    mime="text/csv",
                )

        except Exception as e:
            st.error(f"ì—…ë¡œë“œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

with colB:
    st.subheader("2) ëˆ„ì  ë°˜ì˜ í›„ ì¬í•™ìŠµ (ê´€ë¦¬ì ë²„íŠ¼)")
    st.info(
        "ì´ ë²„íŠ¼ì€ **í˜„ì¬ ì„œë²„ì— ì €ì¥ëœ canonical ë°ì´í„°(master_long.parquet)** ê¸°ì¤€ìœ¼ë¡œ "
        "ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµí•˜ê³  data/models/by_cutoffì— ë®ì–´ì”ë‹ˆë‹¤.\n\n"
        "âš ï¸ ë°ì´í„° ingest(= raw -> canonical)ëŠ” ì´ ë²„íŠ¼ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì•„ìš”. "
        "ìƒˆ raw ë°ì´í„°ë¥¼ canonicalë¡œ ë°˜ì˜í•˜ë ¤ë©´ ingest íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¨¼ì € master_longì„ ì—…ë°ì´íŠ¸í•´ì¤˜ì•¼ í•´ìš”."
    )

    meta = load_meta(cutoff)
    if meta:
        with st.expander("ì„ íƒëœ ëª¨ë¸ ë©”íƒ€ ë³´ê¸°"):
            st.json(meta)

    if st.button("ì¬í•™ìŠµ ì‹¤í–‰", type="secondary"):
        with st.spinner("ì¬í•™ìŠµ ì¤‘... (ë¡œê·¸ ìƒì„± ì¤‘)"):
            code, log = run_retrain(int(min_c), int(max_c))

        st.text_area("í•™ìŠµ ë¡œê·¸", log, height=380)

        if code == 0:
            st.success("ì¬í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ íŒŒì¼ì´ ê°±ì‹ ëì–´ìš”.")
            report_path = PROJECT_ROOT / "data" / "models" / "train_report.csv"
            if report_path.exists():
                rep = pd.read_csv(report_path)
                st.dataframe(rep, use_container_width=True)
        else:
            st.error(f"ì¬í•™ìŠµ ì‹¤íŒ¨ (return code={code}) - ë¡œê·¸ë¥¼ í™•ì¸í•´ì¤˜.")
    # ---- (ì¶”ê°€) ì„œë²„ ëª¨ë¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸ í‘œì‹œ ----
    st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸ (ì„œë²„ í•™ìŠµ ê¸°ì¤€)")

    report_path = PROJECT_ROOT / "data" / "models" / "train_report.csv"
    if report_path.exists():
        rep = pd.read_csv(report_path)

        cols = {c.lower(): c for c in rep.columns}
        cutoff_col = cols.get("cutoff", "cutoff")
        mae_col = cols.get("mae") if ("mae" in cols) else None
        rmse_col = cols.get("rmse") if ("rmse" in cols) else None

        st.dataframe(rep, use_container_width=True)

        if mae_col and cutoff_col in rep.columns:
            st.line_chart(rep.set_index(cutoff_col)[mae_col], height=220)
        if rmse_col and cutoff_col in rep.columns:
            st.line_chart(rep.set_index(cutoff_col)[rmse_col], height=220)
    else:
        st.info("train_report.csvê°€ ì•„ì§ ì—†ì–´ìš”. ì¬í•™ìŠµ ì‹¤í–‰ í›„ ìƒì„±ë©ë‹ˆë‹¤.")
