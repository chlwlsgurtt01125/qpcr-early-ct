"""
Streamlit Appì— ì¶”ê°€í•  Data Catalog ì„¹ì…˜
Long format ë°ì´í„°ë¥¼ Wide formatìœ¼ë¡œ ë³€í™˜í•˜ì—¬ QC ë¶„ì„
âœ… ì»¬ëŸ¼ëª… ìžë™ íƒìƒ‰ ê¸°ëŠ¥ ì¶”ê°€ (robust)
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from typing import Dict, Optional
import os, sys
ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)

from core.data_catalog_integration import render_data_catalog_section


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€ (ê¸°ì¡´ ì•±ê³¼ ë™ì¼í•œ ë°©ì‹)
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from core.qc_analyzer import QPCRQualityControl


def find_column_by_candidates(df: pd.DataFrame, candidates: list, required: bool = True) -> Optional[str]:
    """
    í›„ë³´ ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ ì¡´ìž¬í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
    
    Args:
        df: ë°ì´í„°í”„ë ˆìž„
        candidates: í›„ë³´ ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸ (ìš°ì„ ìˆœìœ„ìˆœ)
        required: Trueë©´ ëª» ì°¾ì„ ë•Œ ì—ëŸ¬, Falseë©´ None ë°˜í™˜
    
    Returns:
        ì°¾ì€ ì»¬ëŸ¼ëª… ë˜ëŠ” None
    """
    # ì •ê·œí™”ëœ ì»¬ëŸ¼ëª… ë”•ì…”ë„ˆë¦¬ (ì†Œë¬¸ìž, ê³µë°±ì œê±°)
    normalized_cols = {col.lower().strip().replace('_', ''): col for col in df.columns}
    
    # í›„ë³´ë“¤ì„ ì •ê·œí™”í•´ì„œ ë§¤ì¹­
    for candidate in candidates:
        normalized_candidate = candidate.lower().strip().replace('_', '')
        if normalized_candidate in normalized_cols:
            return normalized_cols[normalized_candidate]
    
    # ëª» ì°¾ì€ ê²½ìš°
    if required:
        raise ValueError(
            f"Required column not found. Candidates: {candidates}\n"
            f"Available columns: {df.columns.tolist()}"
        )
    return None


def detect_columns_mapping(df_long: pd.DataFrame) -> Dict[str, str]:
    """
    df_longì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…ì„ ìžë™ íƒìƒ‰í•˜ì—¬ ë§¤í•‘
    
    Returns:
        dict: {'fluorescence': 'Fluor', 'cycle': 'Cycle', 'well': 'Well', 'ct': 'Cq', ...}
    """
    mapping = {}
    
    # 1. Fluorescence ì»¬ëŸ¼
    fluor_candidates = ['fluorescence', 'Fluor', 'fluor', 'rfu', 'RFU', 
                       'signal', 'Signal', 'value', 'Value', 'intensity', 'Intensity']
    mapping['fluorescence'] = find_column_by_candidates(df_long, fluor_candidates, required=True)
    
    # 2. Cycle ì»¬ëŸ¼
    cycle_candidates = ['cycle', 'Cycle', 'cycles', 'Cycles', 'cyc']
    mapping['cycle'] = find_column_by_candidates(df_long, cycle_candidates, required=True)
    
    # 3. Well ì»¬ëŸ¼ (well_id ìš°ì„ , ì—†ìœ¼ë©´ well_uid)
    well_candidates = ['well_id', 'Well', 'well', 'well_uid', 'wellid', 'sample_id']
    mapping['well'] = find_column_by_candidates(df_long, well_candidates, required=True)
    
    # 4. Ct/Cq ì»¬ëŸ¼
    ct_candidates = ['cq', 'Cq', 'CQ', 'ct', 'Ct', 'CT', 'ct_value', 'cq_value']
    mapping['ct'] = find_column_by_candidates(df_long, ct_candidates, required=True)
    
    # 5. Run ID ì»¬ëŸ¼ (optional)
    run_candidates = ['run_id', 'Run_ID', 'runid', 'run', 'Run']
    mapping['run_id'] = find_column_by_candidates(df_long, run_candidates, required=False)
    
    # 6. Sample Type ì»¬ëŸ¼ (optional)
    type_candidates = ['sample_type', 'type', 'Type', 'sample_class', 'class']
    mapping['sample_type'] = find_column_by_candidates(df_long, type_candidates, required=False)
    
    return mapping


def long_to_wide_for_qc(df_long: pd.DataFrame) -> pd.DataFrame:
    """
    Long format (run_id, well_id, cycle, fluorescence, cq) 
    â†’ Wide format (well_id, ct_true, cycle_1, cycle_2, ..., cycle_40)
    
    âœ… ì»¬ëŸ¼ëª… ìžë™ íƒìƒ‰ ì¶”ê°€
    
    Args:
        df_long: master_long.parquetì˜ ë°ì´í„°í”„ë ˆìž„
    
    Returns:
        Wide format ë°ì´í„°í”„ë ˆìž„
    """
    # ì»¬ëŸ¼ëª… ë§¤í•‘ ê°ì§€
    col_map = detect_columns_mapping(df_long)
    
    # ì¸ë±ìŠ¤ ì»¬ëŸ¼ ê²°ì •
    index_cols = [col_map['well']]
    if col_map['run_id'] is not None:
        index_cols.insert(0, col_map['run_id'])
    
    # 1. Cycleë³„ í˜•ê´‘ê°’ì„ Wideë¡œ ë³€í™˜
    pivot = df_long.pivot_table(
        index=index_cols,
        columns=col_map['cycle'],
        values=col_map['fluorescence'],
        aggfunc='first'
    ).reset_index()
    
    # ì»¬ëŸ¼ëª… ë³€ê²½: 1,2,3... â†’ cycle_1, cycle_2, ...
    rename_dict = {col: f'cycle_{col}' for col in pivot.columns if isinstance(col, (int, np.integer))}
    pivot.rename(columns=rename_dict, inplace=True)
    
    # well ì»¬ëŸ¼ëª…ì„ 'well_id'ë¡œ í†µì¼
    if col_map['well'] in pivot.columns:
        pivot.rename(columns={col_map['well']: 'well_id'}, inplace=True)
    
    # 2. Ct ê°’ ì¶”ê°€ (ê° wellì˜ ì²« ë²ˆì§¸ cq ê°’)
    ct_df = df_long.groupby(index_cols)[col_map['ct']].first().reset_index()
    ct_df.rename(columns={col_map['ct']: 'ct_true'}, inplace=True)
    
    # well ì»¬ëŸ¼ëª… í†µì¼
    if col_map['well'] in ct_df.columns:
        ct_df.rename(columns={col_map['well']: 'well_id'}, inplace=True)
    
    # 3. ë³‘í•©
    merge_cols = ['well_id']
    if col_map['run_id'] is not None:
        merge_cols.insert(0, col_map['run_id'])
    
    wide_df = pivot.merge(ct_df, on=merge_cols, how='left')
    
    # 4. ìƒ˜í”Œ íƒ€ìž… ì¶”ê°€ (ìžˆë‹¤ë©´)
    if col_map['sample_type'] is not None:
        sample_type = df_long.groupby(index_cols)[col_map['sample_type']].first().reset_index()
        if col_map['well'] in sample_type.columns:
            sample_type.rename(columns={col_map['well']: 'well_id'}, inplace=True)
        wide_df = wide_df.merge(sample_type, on=merge_cols, how='left')
    
    return wide_df


def render_data_catalog_section():
    """
    Streamlit ì•±ì— ì¶”ê°€í•  Data Catalog ì„¹ì…˜
    ê¸°ì¡´ streamlit_app.pyì˜ íƒ­ ë˜ëŠ” ì„¹ì…˜ìœ¼ë¡œ ì¶”ê°€
    """
    st.header("ðŸ“Š Data Catalog & QC Analysis")
    
    st.markdown("""
    ì „ì²´ í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ QC ë¶„ì„ ê²°ê³¼ìž…ë‹ˆë‹¤.
    - **PASS**: ëª¨ë“  QC ê¸°ì¤€ í†µê³¼
    - **FAIL**: í˜•íƒœ ì´ìƒ ë˜ëŠ” ê·¹ë‹¨ì  Ct ê°’
    - **FLAG**: ê²€í†  í•„ìš” (Late Ct, Very Low Ct)
    """)
    
    # === ë°ì´í„° ë¡œë“œ ===
    master_long_path = PROJECT_ROOT / "data" / "canonical" / "master_long.parquet"
    
    if not master_long_path.exists():
        st.warning("master_long.parquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
        return
    
    # === DEBUG EXPANDER ===
    with st.expander("ðŸ”§ Debug Info (Data Structure)", expanded=False):
        try:
            df_debug = pd.read_parquet(master_long_path)
            
            st.write("**Parquet Path:**", str(master_long_path))
            st.write("**Shape:**", df_debug.shape)
            st.write("**Columns:**", df_debug.columns.tolist())
            st.write("**Dtypes:**")
            st.code(str(df_debug.dtypes))
            st.write("**First 5 rows:**")
            st.dataframe(df_debug.head(5), use_container_width=True)
            
            # ì»¬ëŸ¼ ë§¤í•‘ í…ŒìŠ¤íŠ¸
            st.write("**Detected Column Mapping:**")
            try:
                col_map = detect_columns_mapping(df_debug)
                st.json(col_map)
            except Exception as e:
                st.error(f"Column mapping failed: {e}")
                
        except Exception as e:
            st.error(f"Debug info loading failed: {e}")
    
    # ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
    @st.cache_data
    def load_and_analyze_data():
        try:
            # Long format ë¡œë“œ
            df_long = pd.read_parquet(master_long_path)
            
            # Wide formatìœ¼ë¡œ ë³€í™˜
            df_wide = long_to_wide_for_qc(df_long)
            
            # QC ë¶„ì„ ì‹¤í–‰
            qc = QPCRQualityControl()
            catalog = qc.create_catalog(df_wide)
            
            # run_id ì •ë³´ ì¶”ê°€ (ìžˆë‹¤ë©´)
            if 'run_id' in df_wide.columns:
                catalog = catalog.merge(
                    df_wide[['run_id']].reset_index(drop=True),
                    left_on='row_index',
                    right_index=True,
                    how='left'
                )
            
            excluded_report = qc.create_excluded_report(catalog)
            
            return catalog, excluded_report, df_long, df_wide
            
        except Exception as e:
            st.error(f"âŒ Data loading/analysis failed: {str(e)}")
            st.exception(e)
            raise
    
    with st.spinner("ðŸ”¬ QC ë¶„ì„ ì‹¤í–‰ ì¤‘..."):
        try:
            catalog, excluded_report, df_long, df_wide = load_and_analyze_data()
        except Exception as e:
            st.error("ë°ì´í„° ë¡œë“œ ë˜ëŠ” ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ Debug Infoë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return
    
    # === ìš”ì•½ í†µê³„ ===
    st.subheader("ðŸ“ˆ Summary Statistics")
    
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    
    total = len(catalog)
    pass_count = (catalog['qc_status'] == 'PASS').sum()
    fail_count = (catalog['qc_status'] == 'FAIL').sum()
    flag_count = (catalog['qc_status'] == 'FLAG').sum()
    usable_count = catalog['usable'].sum()
    excluded_count = total - usable_count
    
    col1.metric("Total Wells", f"{total:,}")
    col2.metric("âœ… PASS", f"{pass_count:,}", f"{pass_count/total*100:.1f}%")
    col3.metric("âŒ FAIL", f"{fail_count:,}", f"{fail_count/total*100:.1f}%")
    col4.metric("âš ï¸ FLAG", f"{flag_count:,}", f"{flag_count/total*100:.1f}%")
    col5.metric("ðŸŸ¢ Usable", f"{usable_count:,}", f"{usable_count/total*100:.1f}%")
    col6.metric("ðŸ”´ Excluded", f"{excluded_count:,}", f"{excluded_count/total*100:.1f}%")
    
    # === ì‹œê°í™” ===
    st.subheader("ðŸ“Š Visualizations")
    
    viz_col1, viz_col2 = st.columns(2)
    
    with viz_col1:
        # QC Status ë¶„í¬
        status_counts = catalog['qc_status'].value_counts()
        fig_status = px.pie(
            values=status_counts.values,
            names=status_counts.index,
            title="QC Status Distribution",
            color=status_counts.index,
            color_discrete_map={'PASS': 'green', 'FAIL': 'red', 'FLAG': 'orange'}
        )
        st.plotly_chart(fig_status, use_container_width=True)
    
    with viz_col2:
        # Ct Bin ë¶„í¬
        bin_counts = catalog['ct_bin'].value_counts().sort_index()
        fig_bins = px.bar(
            x=bin_counts.index,
            y=bin_counts.values,
            title="Ct Bin Distribution",
            labels={'x': 'Ct Bin', 'y': 'Count'},
            color=bin_counts.values,
            color_continuous_scale='Viridis'
        )
        st.plotly_chart(fig_bins, use_container_width=True)
    
    # === Fail Reason ë¶„ì„ ===
    if excluded_count > 0:
        st.subheader("ðŸ” Exclusion Analysis")
        
        fail_reasons = catalog[~catalog['usable']]['fail_reason'].value_counts().head(10)
        
        fig_reasons = px.bar(
            x=fail_reasons.values,
            y=fail_reasons.index,
            orientation='h',
            title="Top 10 Exclusion Reasons",
            labels={'x': 'Count', 'y': 'Fail Reason'}
        )
        fig_reasons.update_layout(height=400)
        st.plotly_chart(fig_reasons, use_container_width=True)
    
    # === QC Status by Ct Bin ===
    st.subheader("ðŸŽ¯ QC Status by Ct Bin")
    
    status_by_bin = pd.crosstab(catalog['ct_bin'], catalog['qc_status'])
    
    fig_status_bin = px.bar(
        status_by_bin,
        barmode='stack',
        title="QC Status Distribution per Ct Bin",
        labels={'value': 'Count', 'ct_bin': 'Ct Bin'},
        color_discrete_map={'PASS': 'green', 'FAIL': 'red', 'FLAG': 'orange'}
    )
    fig_status_bin.update_layout(height=400)
    st.plotly_chart(fig_status_bin, use_container_width=True)
    
    # === í•„í„°ë§ ë° í…Œì´ë¸” í‘œì‹œ ===
    st.subheader("ðŸ“‹ Master Catalog (Filterable)")
    
    filter_col1, filter_col2, filter_col3 = st.columns(3)
    
    with filter_col1:
        filter_qc_status = st.multiselect(
            "QC Status",
            options=['PASS', 'FAIL', 'FLAG'],
            default=['PASS', 'FAIL', 'FLAG']
        )
    
    with filter_col2:
        filter_ct_bins = st.multiselect(
            "Ct Bin",
            options=sorted(catalog['ct_bin'].unique()),
            default=sorted(catalog['ct_bin'].unique())
        )
    
    with filter_col3:
        if 'run_id' in catalog.columns:
            filter_run = st.multiselect(
                "Run ID",
                options=sorted(catalog['run_id'].unique()),
                default=sorted(catalog['run_id'].unique())
            )
        else:
            filter_run = None
    
    # í•„í„° ì ìš©
    filtered_catalog = catalog[
        (catalog['qc_status'].isin(filter_qc_status)) &
        (catalog['ct_bin'].isin(filter_ct_bins))
    ]
    
    if filter_run is not None and 'run_id' in catalog.columns:
        filtered_catalog = filtered_catalog[filtered_catalog['run_id'].isin(filter_run)]
    
    st.write(f"**Showing {len(filtered_catalog):,} / {len(catalog):,} wells**")
    
    # í…Œì´ë¸” í‘œì‹œ
    display_columns = ['well_id', 'ct_value', 'ct_bin', 'qc_status', 'fail_reason', 
                      'usable', 'r2', 'snr']
    if 'run_id' in filtered_catalog.columns:
        display_columns.insert(0, 'run_id')
    
    st.dataframe(
        filtered_catalog[display_columns].style.format({
            'ct_value': '{:.2f}',
            'r2': '{:.3f}',
            'snr': '{:.2f}'
        }).apply(
            lambda x: ['background-color: #d4edda' if v == 'PASS' else 
                      'background-color: #f8d7da' if v == 'FAIL' else
                      'background-color: #fff3cd' if v == 'FLAG' else ''
                      for v in x],
            subset=['qc_status']
        ),
        use_container_width=True,
        height=400
    )
    
    # === Excluded Report ===
    if len(excluded_report) > 0:
        st.subheader("ðŸš« Excluded Samples Report")
        
        st.write(f"**Total excluded: {len(excluded_report):,} wells**")
        
        # Major reason ë¶„í¬
        major_reason_counts = excluded_report['excluded_major_reason'].value_counts()
        
        fig_major = px.pie(
            values=major_reason_counts.values,
            names=major_reason_counts.index,
            title="Major Exclusion Categories"
        )
        st.plotly_chart(fig_major, use_container_width=True)
        
        # ìƒì„¸ í…Œì´ë¸”
        st.dataframe(
            excluded_report.style.format({
                'evidence_r2': '{:.3f}',
                'evidence_snr': '{:.2f}',
                'evidence_ct': '{:.2f}'
            }),
            use_container_width=True,
            height=400
        )
    
    # === ë‹¤ìš´ë¡œë“œ ===
    st.subheader("ðŸ’¾ Download Reports")
    
    download_col1, download_col2 = st.columns(2)
    
    with download_col1:
        catalog_csv = catalog.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ðŸ“¥ Download Master Catalog (CSV)",
            data=catalog_csv,
            file_name="qpcr_data_catalog.csv",
            mime="text/csv"
        )
    
    with download_col2:
        if len(excluded_report) > 0:
            excluded_csv = excluded_report.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ðŸ“¥ Download Excluded Report (CSV)",
                data=excluded_csv,
                file_name="qpcr_excluded_report.csv",
                mime="text/csv"
            )